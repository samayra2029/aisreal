---
title: "Is the Knowledge Still in Control?"
date: "2025-01-19"
highlights:
  - "We control training data selection, architecture design, safety training, deployment guardrails"
  - "We don't fully understand how specific knowledge is stored internally or why certain capabilities emerge at scale"
  - "It's like understanding a brain — we know the neurons and connections, but understanding the whole system remains elusive"
moral: "We built it, but we don't fully understand it. And that's the honest starting point."
tags: ["control", "emergence", "understanding"]
---

> **Me:** Is the knowledge of these LLMs is still in control

> **AI:** ****Short answer: Partially.****

What we control:

- Training data selection
- Architecture design
- Safety training (RLHF, Constitutional AI)
- Deployment guardrails

What we don't fully understand:

- How specific knowledge is stored internally
- Why certain capabilities emerge at scale
- Exact reasoning paths for complex responses
- Why some prompts work and others don't

It's like understanding a brain — we know the neurons and connections, but "understanding" the whole system remains elusive.
